{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ciA4bEMl4vKj",
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:35.524326Z",
     "start_time": "2023-12-06T14:23:35.517355Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.src.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_data =  \"./data/train\"\n",
    "test_data = \"./data/test\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:37.892417Z",
     "start_time": "2023-12-06T14:23:37.881915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def create_train_dataframe(directory):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    for class_label in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_label)\n",
    "\n",
    "        if os.path.isdir(class_path):\n",
    "            for filename in os.listdir(class_path):\n",
    "                filepath = os.path.join(class_path, filename)\n",
    "                filepaths.append(filepath)\n",
    "                labels.append(class_label)\n",
    "\n",
    "    return pd.DataFrame({'filepath': filepaths, 'label': labels})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:43.428855Z",
     "start_time": "2023-12-06T14:23:43.420745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def create_test_dataframe(folder_path, label = 'test'):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            filepaths.append(filepath)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return pd.DataFrame({\"filepath\": filepaths, \"label\": labels})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:46.552807Z",
     "start_time": "2023-12-06T14:23:46.544769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                           filepath  label\n0  ./data/train/Paper/image_811.jpg  Paper\n1  ./data/train/Paper/image_805.jpg  Paper\n2  ./data/train/Paper/image_193.jpg  Paper\n3  ./data/train/Paper/image_187.jpg  Paper\n4  ./data/train/Paper/image_839.jpg  Paper",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./data/train/Paper/image_811.jpg</td>\n      <td>Paper</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./data/train/Paper/image_805.jpg</td>\n      <td>Paper</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./data/train/Paper/image_193.jpg</td>\n      <td>Paper</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./data/train/Paper/image_187.jpg</td>\n      <td>Paper</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./data/train/Paper/image_839.jpg</td>\n      <td>Paper</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train df:\")\n",
    "train_df = create_train_dataframe(train_data)\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:47.449244Z",
     "start_time": "2023-12-06T14:23:47.436175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test df:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                          filepath label\n0  ./data/test/test_image_1159.jpg  test\n1   ./data/test/test_image_588.jpg  test\n2  ./data/test/test_image_1165.jpg  test\n3  ./data/test/test_image_1171.jpg  test\n4   ./data/test/test_image_239.jpg  test",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./data/test/test_image_1159.jpg</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./data/test/test_image_588.jpg</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./data/test/test_image_1165.jpg</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./data/test/test_image_1171.jpg</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./data/test/test_image_239.jpg</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test df:\")\n",
    "test_df = create_test_dataframe(test_data)\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:48.179594Z",
     "start_time": "2023-12-06T14:23:48.169769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "IMG_SIZE = 100\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:50.385305Z",
     "start_time": "2023-12-06T14:23:50.380038Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:52.450099Z",
     "start_time": "2023-12-06T14:23:52.442146Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=1234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:30.674996Z",
     "start_time": "2023-12-06T14:23:30.638311Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "results_base = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"history\": []\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:57.438606Z",
     "start_time": "2023-12-06T14:23:57.434334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "epochs = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:58.868040Z",
     "start_time": "2023-12-06T14:23:58.857359Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2016 validated image filenames belonging to 3 classes.\n",
      "Found 504 validated image filenames belonging to 3 classes.\n",
      "Found 630 validated image filenames belonging to 3 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 43\u001B[0m\n\u001B[1;32m     31\u001B[0m test_generator \u001B[38;5;241m=\u001B[39m test_datagen\u001B[38;5;241m.\u001B[39mflow_from_dataframe(\n\u001B[1;32m     32\u001B[0m     dataframe\u001B[38;5;241m=\u001B[39mtest_data,\n\u001B[1;32m     33\u001B[0m     x_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfilepath\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     38\u001B[0m     color_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrayscale\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     39\u001B[0m )\n\u001B[1;32m     41\u001B[0m model \u001B[38;5;241m=\u001B[39m cnn_model()\n\u001B[0;32m---> 43\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_generator\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m results_base[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhistory\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(history)\n\u001B[1;32m     51\u001B[0m y_true \u001B[38;5;241m=\u001B[39m test_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:888\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    885\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    886\u001B[0m   \u001B[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001B[39;00m\n\u001B[1;32m    887\u001B[0m   initializers \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 888\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_initializers_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitializers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    890\u001B[0m   \u001B[38;5;66;03m# At this point we know that the initialization is complete (or less\u001B[39;00m\n\u001B[1;32m    891\u001B[0m   \u001B[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001B[39;00m\n\u001B[1;32m    892\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001B[0m, in \u001B[0;36mFunction._initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_scoped_tracing_options(\n\u001B[1;32m    691\u001B[0m     variable_capturing_scope,\n\u001B[1;32m    692\u001B[0m     tracing_compilation\u001B[38;5;241m.\u001B[39mScopeType\u001B[38;5;241m.\u001B[39mVARIABLE_CREATION,\n\u001B[1;32m    693\u001B[0m )\n\u001B[1;32m    694\u001B[0m \u001B[38;5;66;03m# Force the definition of the function for these arguments\u001B[39;00m\n\u001B[0;32m--> 695\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_variable_creation_fn \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrace_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvalid_creator_scope\u001B[39m(\u001B[38;5;241m*\u001B[39munused_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munused_kwds):\n\u001B[1;32m    700\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001B[0m, in \u001B[0;36mtrace_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    175\u001B[0m     args \u001B[38;5;241m=\u001B[39m tracing_options\u001B[38;5;241m.\u001B[39minput_signature\n\u001B[1;32m    176\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 178\u001B[0m   concrete_function \u001B[38;5;241m=\u001B[39m \u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mbind_graph_to_function:\n\u001B[1;32m    183\u001B[0m   concrete_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001B[0m, in \u001B[0;36m_maybe_define_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    282\u001B[0m   target_func_type \u001B[38;5;241m=\u001B[39m lookup_func_type\n\u001B[0;32m--> 283\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_func_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookup_func_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mfunction_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    288\u001B[0m   tracing_options\u001B[38;5;241m.\u001B[39mfunction_cache\u001B[38;5;241m.\u001B[39madd(\n\u001B[1;32m    289\u001B[0m       concrete_function, current_func_context\n\u001B[1;32m    290\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001B[0m, in \u001B[0;36m_create_concrete_function\u001B[0;34m(function_type, type_context, func_graph, tracing_options)\u001B[0m\n\u001B[1;32m    303\u001B[0m   placeholder_bound_args \u001B[38;5;241m=\u001B[39m function_type\u001B[38;5;241m.\u001B[39mplaceholder_arguments(\n\u001B[1;32m    304\u001B[0m       placeholder_context\n\u001B[1;32m    305\u001B[0m   )\n\u001B[1;32m    307\u001B[0m disable_acd \u001B[38;5;241m=\u001B[39m tracing_options\u001B[38;5;241m.\u001B[39mattributes \u001B[38;5;129;01mand\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mattributes\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m    308\u001B[0m     attributes_lib\u001B[38;5;241m.\u001B[39mDISABLE_ACD, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    309\u001B[0m )\n\u001B[0;32m--> 310\u001B[0m traced_func_graph \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpython_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_control_dependencies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdisable_acd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction_type_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_arg_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    322\u001B[0m transform\u001B[38;5;241m.\u001B[39mapply_func_graph_transforms(traced_func_graph)\n\u001B[1;32m    324\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m traced_func_graph\u001B[38;5;241m.\u001B[39mfunction_captures\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1059\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001B[0m\n\u001B[1;32m   1056\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m   1058\u001B[0m _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[0;32m-> 1059\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[1;32m   1063\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001B[0m, in \u001B[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m default_graph\u001B[38;5;241m.\u001B[39m_variable_creator_scope(scope, priority\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    595\u001B[0m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[1;32m    596\u001B[0m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[1;32m    597\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[0;32m--> 598\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mweak_wrapped_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__wrapped__\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    599\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001B[0m, in \u001B[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 41\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m      \u001B[49m\u001B[43moriginal_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m      \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m      \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConversionOptions\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m          \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m          \u001B[49m\u001B[43moptional_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mautograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m          \u001B[49m\u001B[43muser_requested\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m     51\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    438\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 439\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mconverted_f\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43meffective_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    441\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args)\n",
      "File \u001B[0;32m/var/folders/q2/p55hxgdx4lv045gkp_750n_m0000gn/T/__autograph_generated_file3s5ry56k.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_function\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[0;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:460\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/training.py:1384\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m   1380\u001B[0m     run_step \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfunction(\n\u001B[1;32m   1381\u001B[0m         run_step, jit_compile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, reduce_retracing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1382\u001B[0m     )\n\u001B[1;32m   1383\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(iterator)\n\u001B[0;32m-> 1384\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1385\u001B[0m outputs \u001B[38;5;241m=\u001B[39m reduce_per_replica(\n\u001B[1;32m   1386\u001B[0m     outputs,\n\u001B[1;32m   1387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy,\n\u001B[1;32m   1388\u001B[0m     reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_reduction_method,\n\u001B[1;32m   1389\u001B[0m )\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001B[0m, in \u001B[0;36mStrategyBase.run\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1676\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m   1677\u001B[0m   \u001B[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001B[39;00m\n\u001B[1;32m   1678\u001B[0m   \u001B[38;5;66;03m# applied when the caller is also in Eager mode.\u001B[39;00m\n\u001B[1;32m   1679\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   1680\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 1681\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extended\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001B[0m, in \u001B[0;36mStrategyExtendedV1.call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3269\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   3270\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m-> 3271\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_for_each_replica\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   4067\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_for_each_replica\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[1;32m   4068\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ReplicaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy(), replica_id_in_sync_group\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m-> 4069\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[0;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/training.py:1373\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m   1372\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(data):\n\u001B[0;32m-> 1373\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1374\u001B[0m     \u001B[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001B[39;00m\n\u001B[1;32m   1375\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/training.py:1150\u001B[0m, in \u001B[0;36mModel.train_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1148\u001B[0m \u001B[38;5;66;03m# Run forward pass.\u001B[39;00m\n\u001B[1;32m   1149\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[0;32m-> 1150\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1151\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001B[1;32m   1152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_target_and_loss(y, loss)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/training.py:590\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    586\u001B[0m         \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(inputs, \u001B[38;5;241m*\u001B[39mcopied_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcopied_kwargs)\n\u001B[1;32m    588\u001B[0m     layout_map_lib\u001B[38;5;241m.\u001B[39m_map_subclass_model_variable(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layout_map)\n\u001B[0;32m--> 590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/base_layer.py:1149\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[1;32m   1148\u001B[0m ):\n\u001B[0;32m-> 1149\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[0;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/sequential.py:398\u001B[0m, in \u001B[0;36mSequential.call\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    396\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuilt:\n\u001B[1;32m    397\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_graph_network(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs)\n\u001B[0;32m--> 398\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    400\u001B[0m outputs \u001B[38;5;241m=\u001B[39m inputs  \u001B[38;5;66;03m# handle the corner case where self.layers is empty\u001B[39;00m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;66;03m# During each iteration, `inputs` are the inputs to `layer`, and\u001B[39;00m\n\u001B[1;32m    403\u001B[0m     \u001B[38;5;66;03m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001B[39;00m\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;66;03m# end of each iteration `inputs` is set to `outputs` to prepare for\u001B[39;00m\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;66;03m# the next layer.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/functional.py:515\u001B[0m, in \u001B[0;36mFunctional.call\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    496\u001B[0m \u001B[38;5;129m@doc_controls\u001B[39m\u001B[38;5;241m.\u001B[39mdo_not_doc_inheritable\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    498\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Calls the model on new inputs.\u001B[39;00m\n\u001B[1;32m    499\u001B[0m \n\u001B[1;32m    500\u001B[0m \u001B[38;5;124;03m    In this case `call` just reapplies\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;124;03m        a list of tensors if there are more than one outputs.\u001B[39;00m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 515\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_internal_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/functional.py:672\u001B[0m, in \u001B[0;36mFunctional._run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    669\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# Node is not computable, try skipping.\u001B[39;00m\n\u001B[1;32m    671\u001B[0m args, kwargs \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39mmap_arguments(tensor_dict)\n\u001B[0;32m--> 672\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[38;5;66;03m# Update tensor_dict.\u001B[39;00m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_id, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\n\u001B[1;32m    676\u001B[0m     node\u001B[38;5;241m.\u001B[39mflat_output_ids, tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(outputs)\n\u001B[1;32m    677\u001B[0m ):\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/engine/base_layer.py:1149\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object\n\u001B[1;32m   1148\u001B[0m ):\n\u001B[0;32m-> 1149\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:96\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     99\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:331\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_in_allowlist_cache(f, options):\n\u001B[1;32m    330\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: from cache\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n\u001B[0;32m--> 331\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m ag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mDISABLED:\n\u001B[1;32m    334\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: AutoGraph is disabled in context\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:290\u001B[0m, in \u001B[0;36mConv.call\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    286\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compiled_convolution_op(\n\u001B[1;32m    287\u001B[0m         inputs, tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel)\n\u001B[1;32m    288\u001B[0m     )\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 290\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvolution_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_bias:\n\u001B[1;32m    293\u001B[0m     output_rank \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mrank\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:262\u001B[0m, in \u001B[0;36mConv.convolution_op\u001B[0;34m(self, inputs, kernel)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    260\u001B[0m     tf_padding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding\n\u001B[0;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvolution\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf_padding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation_rate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tf_data_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1258\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1260\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1262\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1264\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:1186\u001B[0m, in \u001B[0;36mconvolution_v2\u001B[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001B[0m\n\u001B[1;32m   1176\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnn.convolution\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvolution_v2\u001B[39m(  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1184\u001B[0m     dilations\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1185\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m-> 1186\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconvolution_internal\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1187\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=redefined-builtin\u001B[39;49;00m\n\u001B[1;32m   1188\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1189\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1190\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1192\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:1319\u001B[0m, in \u001B[0;36mconvolution_internal\u001B[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001B[0m\n\u001B[1;32m   1316\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1317\u001B[0m     op \u001B[38;5;241m=\u001B[39m conv1d\n\u001B[0;32m-> 1319\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1320\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1321\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1326\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1327\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1328\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m channel_index \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:2793\u001B[0m, in \u001B[0;36m_conv2d_expanded_batch\u001B[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001B[0m\n\u001B[1;32m   2789\u001B[0m input_rank \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mrank\n\u001B[1;32m   2790\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_rank \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m input_rank \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m5\u001B[39m:\n\u001B[1;32m   2791\u001B[0m   \u001B[38;5;66;03m# We avoid calling squeeze_batch_dims to reduce extra python function\u001B[39;00m\n\u001B[1;32m   2792\u001B[0m   \u001B[38;5;66;03m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001B[39;00m\n\u001B[0;32m-> 2793\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_nn_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2794\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2795\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2796\u001B[0m \u001B[43m      \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2797\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2798\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2799\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2800\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2801\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m squeeze_batch_dims(\n\u001B[1;32m   2802\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   2803\u001B[0m     functools\u001B[38;5;241m.\u001B[39mpartial(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2810\u001B[0m     inner_rank\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m   2811\u001B[0m     name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py:1378\u001B[0m, in \u001B[0;36mconv2d\u001B[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001B[0m\n\u001B[1;32m   1374\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   1375\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected list for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdilations\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m argument to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1376\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconv2d\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Op, not \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m dilations)\n\u001B[1;32m   1377\u001B[0m dilations \u001B[38;5;241m=\u001B[39m [_execute\u001B[38;5;241m.\u001B[39mmake_int(_i, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdilations\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m _i \u001B[38;5;129;01min\u001B[39;00m dilations]\n\u001B[0;32m-> 1378\u001B[0m _, _, _op, _outputs \u001B[38;5;241m=\u001B[39m \u001B[43m_op_def_library\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_op_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1379\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mConv2D\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1380\u001B[0m \u001B[43m                \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1381\u001B[0m \u001B[43m                \u001B[49m\u001B[43mexplicit_paddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexplicit_paddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1382\u001B[0m \u001B[43m                \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1383\u001B[0m _result \u001B[38;5;241m=\u001B[39m _outputs[:]\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _execute\u001B[38;5;241m.\u001B[39mmust_record_gradient():\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:778\u001B[0m, in \u001B[0;36m_apply_op_helper\u001B[0;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[1;32m    776\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m g\u001B[38;5;241m.\u001B[39mas_default(), ops\u001B[38;5;241m.\u001B[39mname_scope(name) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[1;32m    777\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m fallback:\n\u001B[0;32m--> 778\u001B[0m     \u001B[43m_ExtractInputsAndAttrs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_type_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallowed_list_attr_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    779\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mkeywords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault_type_attr_map\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    780\u001B[0m \u001B[43m                           \u001B[49m\u001B[43minput_types\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001B[1;32m    782\u001B[0m                            default_type_attr_map, attrs)\n\u001B[1;32m    783\u001B[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:551\u001B[0m, in \u001B[0;36m_ExtractInputsAndAttrs\u001B[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001B[0m\n\u001B[1;32m    545\u001B[0m       values \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(\n\u001B[1;32m    546\u001B[0m           values,\n\u001B[1;32m    547\u001B[0m           name\u001B[38;5;241m=\u001B[39minput_arg\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m    548\u001B[0m           as_ref\u001B[38;5;241m=\u001B[39minput_arg\u001B[38;5;241m.\u001B[39mis_ref,\n\u001B[1;32m    549\u001B[0m           preferred_dtype\u001B[38;5;241m=\u001B[39mdefault_dtype)\n\u001B[1;32m    550\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 551\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_arg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m        \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_arg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_ref\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreferred_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    558\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001B[0m, in \u001B[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    181\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m Trace(trace_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrace_kwargs):\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:696\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001B[39;00m\n\u001B[1;32m    695\u001B[0m preferred_dtype \u001B[38;5;241m=\u001B[39m preferred_dtype \u001B[38;5;129;01mor\u001B[39;00m dtype_hint\n\u001B[0;32m--> 696\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor_conversion_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreferred_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccepted_result_types\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001B[0m, in \u001B[0;36mconvert\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001B[0m\n\u001B[1;32m    225\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    226\u001B[0m           _add_error_prefix(\n\u001B[1;32m    227\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConversion function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconversion_func\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    230\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mactual = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mret\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mbase_dtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    231\u001B[0m               name\u001B[38;5;241m=\u001B[39mname))\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 234\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mconversion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[1;32m    237\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:2340\u001B[0m, in \u001B[0;36m_dense_var_to_tensor\u001B[0;34m(var, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m   2339\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_dense_var_to_tensor\u001B[39m(var, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, as_ref\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m-> 2340\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dense_var_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1582\u001B[0m, in \u001B[0;36mBaseResourceVariable._dense_var_to_tensor\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1580\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_value()\u001B[38;5;241m.\u001B[39mop\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1581\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1582\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:634\u001B[0m, in \u001B[0;36mBaseResourceVariable.value\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    632\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_value\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28;01mNone\u001B[39;00m, ignore_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 634\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_variable_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:818\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op\u001B[0;34m(self, no_copy)\u001B[0m\n\u001B[1;32m    816\u001B[0m       result \u001B[38;5;241m=\u001B[39m read_and_set_handle(no_copy)\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 818\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mread_and_set_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mno_copy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m    821\u001B[0m   \u001B[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001B[39;00m\n\u001B[1;32m    822\u001B[0m   \u001B[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001B[39;00m\n\u001B[1;32m    823\u001B[0m   record\u001B[38;5;241m.\u001B[39mrecord_operation(\n\u001B[1;32m    824\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReadVariableOp\u001B[39m\u001B[38;5;124m\"\u001B[39m, [result], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle],\n\u001B[1;32m    825\u001B[0m       backward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x],\n\u001B[1;32m    826\u001B[0m       forward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x])\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:808\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001B[0;34m(no_copy)\u001B[0m\n\u001B[1;32m    806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m no_copy \u001B[38;5;129;01mand\u001B[39;00m forward_compat\u001B[38;5;241m.\u001B[39mforward_compatible(\u001B[38;5;241m2022\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m    807\u001B[0m   gen_resource_variable_ops\u001B[38;5;241m.\u001B[39mdisable_copy_on_read(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle)\n\u001B[0;32m--> 808\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mgen_resource_variable_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_variable_op\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    809\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    810\u001B[0m _maybe_set_handle_data(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dtype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, result)\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:548\u001B[0m, in \u001B[0;36mread_variable_op\u001B[0;34m(resource, dtype, name)\u001B[0m\n\u001B[1;32m    546\u001B[0m \u001B[38;5;66;03m# Add nodes to the TensorFlow graph.\u001B[39;00m\n\u001B[1;32m    547\u001B[0m dtype \u001B[38;5;241m=\u001B[39m _execute\u001B[38;5;241m.\u001B[39mmake_type(dtype, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 548\u001B[0m _, _, _op, _outputs \u001B[38;5;241m=\u001B[39m \u001B[43m_op_def_library\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_op_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mReadVariableOp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresource\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    550\u001B[0m _result \u001B[38;5;241m=\u001B[39m _outputs[:]\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _execute\u001B[38;5;241m.\u001B[39mmust_record_gradient():\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:796\u001B[0m, in \u001B[0;36m_apply_op_helper\u001B[0;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[1;32m    791\u001B[0m must_colocate_inputs \u001B[38;5;241m=\u001B[39m [val \u001B[38;5;28;01mfor\u001B[39;00m arg, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(op_def\u001B[38;5;241m.\u001B[39minput_arg, inputs)\n\u001B[1;32m    792\u001B[0m                         \u001B[38;5;28;01mif\u001B[39;00m arg\u001B[38;5;241m.\u001B[39mis_ref]\n\u001B[1;32m    793\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001B[1;32m    794\u001B[0m   \u001B[38;5;66;03m# Add Op to graph\u001B[39;00m\n\u001B[1;32m    795\u001B[0m   \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m--> 796\u001B[0m   op \u001B[38;5;241m=\u001B[39m \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_op_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_type_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscope\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattr_protos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop_def\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001B[39;00m\n\u001B[1;32m    801\u001B[0m \u001B[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001B[39;00m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001B[39;00m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;66;03m# for more details.\u001B[39;00m\n\u001B[1;32m    804\u001B[0m outputs \u001B[38;5;241m=\u001B[39m op\u001B[38;5;241m.\u001B[39moutputs\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:670\u001B[0m, in \u001B[0;36mFuncGraph._create_op_internal\u001B[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[1;32m    668\u001B[0m   inp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcapture(inp)\n\u001B[1;32m    669\u001B[0m   captured_inputs\u001B[38;5;241m.\u001B[39mappend(inp)\n\u001B[0;32m--> 670\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_op_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mop_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_device\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2652\u001B[0m, in \u001B[0;36mGraph._create_op_internal\u001B[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[1;32m   2649\u001B[0m \u001B[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001B[39;00m\n\u001B[1;32m   2650\u001B[0m \u001B[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001B[39;00m\n\u001B[1;32m   2651\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mutation_lock():\n\u001B[0;32m-> 2652\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mOperation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_node_def\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2653\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnode_def\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2654\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2655\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2656\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2657\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcontrol_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontrol_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2658\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2659\u001B[0m \u001B[43m      \u001B[49m\u001B[43moriginal_op\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_default_original_op\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2660\u001B[0m \u001B[43m      \u001B[49m\u001B[43mop_def\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop_def\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2661\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2662\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_op_helper(ret, compute_device\u001B[38;5;241m=\u001B[39mcompute_device)\n\u001B[1;32m   2663\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1160\u001B[0m, in \u001B[0;36mOperation.from_node_def\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1157\u001B[0m     control_input_ops\u001B[38;5;241m.\u001B[39mappend(control_op)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;66;03m# Initialize c_op from node_def and other inputs\u001B[39;00m\n\u001B[0;32m-> 1160\u001B[0m c_op \u001B[38;5;241m=\u001B[39m \u001B[43m_create_c_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode_def\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontrol_input_ops\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_def\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop_def\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m Operation(c_op, SymbolicTensor)\n\u001B[1;32m   1162\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init(g)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/neural_networks/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1017\u001B[0m, in \u001B[0;36m_create_c_op\u001B[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001B[0m\n\u001B[1;32m   1013\u001B[0m   pywrap_tf_session\u001B[38;5;241m.\u001B[39mTF_SetAttrValueProto(op_desc, compat\u001B[38;5;241m.\u001B[39mas_str(name),\n\u001B[1;32m   1014\u001B[0m                                          serialized)\n\u001B[1;32m   1016\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1017\u001B[0m   c_op \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_FinishOperation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_desc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1018\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mInvalidArgumentError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1019\u001B[0m   \u001B[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001B[39;00m\n\u001B[1;32m   1020\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(e\u001B[38;5;241m.\u001B[39mmessage)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for train_index, test_index in k_fold.split(train_df):\n",
    "    train_data = train_df.iloc[train_index]\n",
    "    test_data = train_df.iloc[test_index]\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        x_col=\"filepath\",\n",
    "        y_col=\"label\",\n",
    "        subset=\"training\",\n",
    "        batch_size=batch_size,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=True,\n",
    "        seed=1234,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_dataframe(\n",
    "      dataframe=train_data,\n",
    "      x_col=\"filepath\",\n",
    "      y_col=\"label\",\n",
    "      subset=\"validation\",\n",
    "      batch_size=batch_size,\n",
    "      target_size=(IMG_SIZE, IMG_SIZE),\n",
    "      shuffle=True,\n",
    "      seed=1234,\n",
    "      color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        x_col=\"filepath\",\n",
    "        y_col=\"label\",\n",
    "        batch_size=1,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=False,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "    model = cnn_model()\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator\n",
    "    )\n",
    "\n",
    "    results_base['history'].append(history)\n",
    "\n",
    "    y_true = test_data['label']\n",
    "    y_pred = model.predict(test_generator)\n",
    "\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    class_indices_list = list(test_generator.class_indices.keys())\n",
    "    y_pred_classes = [class_indices_list[i] for i in y_pred_classes]\n",
    "\n",
    "    report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
    "\n",
    "    results_base['accuracy'].append(report['accuracy'])\n",
    "    results_base['precision'].append(report['macro avg']['precision'])\n",
    "    results_base['recall'].append(report['macro avg']['recall'])\n",
    "    results_base['f1'].append(report['macro avg']['f1-score'])\n",
    "\n",
    "    print(report)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:23:33.449672Z",
     "start_time": "2023-12-06T14:23:30.655063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs_fig = range(1, epochs + 1)\n",
    "fig, axs = plt.subplots(5, 2, figsize=(15, 20))\n",
    "\n",
    "for i, history in enumerate(results_base['history']):\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    axs[i, 0].plot(epochs_fig, train_acc, 'b', label=f'Fold {i+1} Training accuracy')\n",
    "    axs[i, 0].plot(epochs_fig, val_acc, 'r', label=f'Fold {i+1} Validation accuracy')\n",
    "    axs[i, 0].set_title(f'Fold {i+1} Accuracy')\n",
    "    axs[i, 0].set_xlabel('Epochs')\n",
    "    axs[i, 0].set_ylabel('Accuracy')\n",
    "    axs[i, 0].legend()\n",
    "\n",
    "    axs[i, 1].plot(epochs_fig, train_loss, 'b', label=f'Fold {i+1} Training loss')\n",
    "    axs[i, 1].plot(epochs_fig, val_loss, 'r', label=f'Fold {i+1} Validation loss')\n",
    "    axs[i, 1].set_title(f'Fold {i+1} Loss')\n",
    "    axs[i, 1].set_xlabel('Epochs')\n",
    "    axs[i, 1].set_ylabel('Loss')\n",
    "    axs[i, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-06T14:23:33.445509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def advanced_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    optimizer = Adagrad(learning_rate=0.01)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-06T14:23:33.445833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_advanced = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"history\": []\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-06T14:23:33.445937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for train_index, test_index in k_fold.split(train_df):\n",
    "    train_data = train_df.iloc[train_index]\n",
    "    test_data = train_df.iloc[test_index]\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        x_col=\"filepath\",\n",
    "        y_col=\"label\",\n",
    "        subset=\"training\",\n",
    "        batch_size=batch_size,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=True,\n",
    "        seed=1234,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_dataframe(\n",
    "      dataframe=train_data,\n",
    "      x_col=\"filepath\",\n",
    "      y_col=\"label\",\n",
    "      subset=\"validation\",\n",
    "      batch_size=batch_size,\n",
    "      target_size=(IMG_SIZE, IMG_SIZE),\n",
    "      shuffle=True,\n",
    "      seed=1234,\n",
    "      color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        x_col=\"filepath\",\n",
    "        y_col=\"label\",\n",
    "        batch_size=1,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=False,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "    model = advanced_cnn_model()\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator\n",
    "    )\n",
    "\n",
    "    results_advanced['history'].append(history)\n",
    "    \n",
    "    y_true = test_data['label']\n",
    "    y_pred = model.predict(test_generator)\n",
    "\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    class_indices_list = list(test_generator.class_indices.keys())\n",
    "    y_pred_classes = [class_indices_list[i] for i in y_pred_classes]\n",
    "\n",
    "    report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
    "    \n",
    "    results_advanced['accuracy'].append(report['accuracy'])\n",
    "    results_advanced['precision'].append(report['macro avg']['precision'])\n",
    "    results_advanced['recall'].append(report['macro avg']['recall'])\n",
    "    results_advanced['f1'].append(report['macro avg']['f1-score'])\n",
    "    \n",
    "    print(report)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-06T14:23:33.446401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"base\": results_base,\n",
    "    \"advanced\": results_advanced\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-06T14:23:33.447347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "models = [\"base\", \"advanced\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.boxplot([results[\"base\"][metric], results[\"advanced\"][metric]], labels=models)\n",
    "    plt.title(metric)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-06T14:23:33.449280Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "      ax = axs[i]\n",
    "      max = -float('inf')\n",
    "      \n",
    "      for j, model in enumerate(models):\n",
    "          values = results[model][metric]\n",
    "          \n",
    "          if len(values) == 0:\n",
    "            values = [0]\n",
    "          \n",
    "          avg = np.mean(values)\n",
    "       \n",
    "          if avg > max:\n",
    "            max = avg\n",
    "              \n",
    "          ax.bar(j, avg, 0.8, label=model)\n",
    "          ax.text(j, avg + 0.01, str(round(avg, 3)), ha='center', va='bottom')\n",
    "\n",
    "\n",
    "      ax.set_ylim([0, max * 1.09])\n",
    "      ax.set_title(f'{metric}')\n",
    "      ax.set_xticks([], [])\n",
    "      ax.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-06T14:23:33.451300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 validated image filenames belonging to 3 classes.\n",
      "Found 630 validated image filenames belonging to 3 classes.\n",
      "Found 1350 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    subset=\"training\",\n",
    "    batch_size=batch_size,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=1234,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "  dataframe=train_df,\n",
    "  x_col=\"filepath\",\n",
    "  y_col=\"label\",\n",
    "  subset=\"validation\",\n",
    "  batch_size=batch_size,\n",
    "  target_size=(IMG_SIZE, IMG_SIZE),\n",
    "  shuffle=True,\n",
    "  seed=1234,\n",
    "  color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=1, \n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=False,\n",
    "    color_mode='grayscale'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:24:17.354167Z",
     "start_time": "2023-12-06T14:24:17.305951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model = cnn_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:24:20.260696Z",
     "start_time": "2023-12-06T14:24:20.196315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 4s 43ms/step - loss: 0.9400 - accuracy: 0.5286 - val_loss: 0.9191 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.3589 - accuracy: 0.8698 - val_loss: 0.2913 - val_accuracy: 0.9127\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1625 - accuracy: 0.9484 - val_loss: 0.2096 - val_accuracy: 0.9190\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1053 - accuracy: 0.9714 - val_loss: 0.2278 - val_accuracy: 0.9143\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0918 - accuracy: 0.9683 - val_loss: 0.0811 - val_accuracy: 0.9746\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0635 - accuracy: 0.9790 - val_loss: 0.1129 - val_accuracy: 0.9587\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 0.0928 - val_accuracy: 0.9667\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0562 - accuracy: 0.9790 - val_loss: 0.5913 - val_accuracy: 0.7746\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.0983 - val_accuracy: 0.9683\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.0534 - val_accuracy: 0.9825\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.1027 - val_accuracy: 0.9714\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.0971 - val_accuracy: 0.9762\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.1134 - val_accuracy: 0.9667\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.0841 - val_accuracy: 0.9683\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1659 - val_accuracy: 0.9571\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0660 - val_accuracy: 0.9857\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0378 - accuracy: 0.9873 - val_loss: 0.1246 - val_accuracy: 0.9556\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0307 - accuracy: 0.9913 - val_loss: 0.1707 - val_accuracy: 0.9508\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.1136 - val_accuracy: 0.9698\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0388 - val_accuracy: 0.9873\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.0727 - val_accuracy: 0.9841\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0538 - val_accuracy: 0.9905\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0801 - val_accuracy: 0.9825\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9857\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 0.0824 - val_accuracy: 0.9857\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1487 - val_accuracy: 0.9698\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9762\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 0.1152 - val_accuracy: 0.9762\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 6.8167e-04 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9889\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 5.7270e-04 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9746\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0745 - val_accuracy: 0.9825\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.1357 - val_accuracy: 0.9667\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1249 - val_accuracy: 0.9698\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.2347 - val_accuracy: 0.9444\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.0409 - val_accuracy: 0.9889\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0953 - val_accuracy: 0.9746\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0104 - accuracy: 0.9960 - val_loss: 0.0439 - val_accuracy: 0.9889\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0072 - accuracy: 0.9964 - val_loss: 0.0276 - val_accuracy: 0.9857\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.1112 - val_accuracy: 0.9730\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0643 - val_accuracy: 0.9810\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0105 - accuracy: 0.9956 - val_loss: 0.0440 - val_accuracy: 0.9810\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0301 - accuracy: 0.9929 - val_loss: 0.0421 - val_accuracy: 0.9841\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0206 - val_accuracy: 0.9952\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 7.8678e-04 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9810\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 7.0512e-04 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9794\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.0953 - val_accuracy: 0.9762\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.1139 - val_accuracy: 0.9730\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 6.0813e-04 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9810\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 4.3183e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9873\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 2.4868e-04 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9794\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 1.3156e-04 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9841\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 1.5287e-04 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9905\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 1.9749e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9794\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 2.6198e-04 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9841\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1153 - val_accuracy: 0.9746\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.2559 - val_accuracy: 0.9571\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.1764 - val_accuracy: 0.9524\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.1557 - val_accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0129 - accuracy: 0.9940 - val_loss: 0.0255 - val_accuracy: 0.9905\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.1277 - val_accuracy: 0.9762\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 8.9935e-04 - accuracy: 0.9996 - val_loss: 0.1652 - val_accuracy: 0.9714\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 4.6009e-04 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9794\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0748 - val_accuracy: 0.9825\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0496 - val_accuracy: 0.9873\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 4.7649e-04 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9794\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.1191 - val_accuracy: 0.9762\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.1241 - val_accuracy: 0.9794\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 4.6786e-04 - accuracy: 0.9996 - val_loss: 0.1229 - val_accuracy: 0.9794\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0875 - val_accuracy: 0.9810\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.1548 - val_accuracy: 0.9730\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0090 - accuracy: 0.9960 - val_loss: 0.3227 - val_accuracy: 0.9476\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.1000 - val_accuracy: 0.9857\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0631 - val_accuracy: 0.9905\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.0472 - val_accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.1452 - val_accuracy: 0.9746\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 2.5726e-04 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9778\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 1.0093e-04 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9825\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0349 - val_accuracy: 0.9921\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1174 - val_accuracy: 0.9825\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.2937 - val_accuracy: 0.9429\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.1077 - val_accuracy: 0.9762\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.0253 - accuracy: 0.9944 - val_loss: 0.0238 - val_accuracy: 0.9937\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0178 - accuracy: 0.9960 - val_loss: 0.2534 - val_accuracy: 0.9492\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9825\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 3.1709e-04 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9841\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 3.0875e-04 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9841\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1460 - val_accuracy: 0.9730\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.0794 - val_accuracy: 0.9857\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 0.1067 - val_accuracy: 0.9810\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 3.3198e-04 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9825\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 8.5978e-05 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9841\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 6.1223e-05 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9841\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 6.4179e-05 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9825\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.1811 - val_accuracy: 0.9651\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.1464 - val_accuracy: 0.9683\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 9.2567e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9794\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 2.6370e-04 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9841\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.1621 - val_accuracy: 0.9730\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.0731 - val_accuracy: 0.9873\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.3112 - val_accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:29:36.879131Z",
     "start_time": "2023-12-06T14:24:21.374969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train accuracy:  0.9899999976158143\n",
      "Average train loss:  0.025697984551879927\n",
      "Average val accuracy:  0.9684761762619019\n",
      "Average val loss:  0.12292823862284422\n"
     ]
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print(\"Average train accuracy: \", np.mean(train_acc))\n",
    "print(\"Average train loss: \", np.mean(train_loss))\n",
    "print(\"Average val accuracy: \", np.mean(val_acc))\n",
    "print(\"Average val loss: \", np.mean(val_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:29:42.619158Z",
     "start_time": "2023-12-06T14:29:42.613225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350/1350 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:29:46.224360Z",
     "start_time": "2023-12-06T14:29:43.658476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Paper', 'Rock', 'Scissors']\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "class_indices_list = list(train_generator.class_indices.keys())\n",
    "print(class_indices_list)\n",
    "y_pred_classes = [class_indices_list[i] for i in y_pred_classes]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:29:47.887724Z",
     "start_time": "2023-12-06T14:29:47.879473Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                 image predicted_class\n0  test_image_1159.jpg            Rock\n1   test_image_588.jpg            Rock\n2  test_image_1165.jpg           Paper\n3  test_image_1171.jpg        Scissors\n4   test_image_239.jpg           Paper",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>predicted_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_image_1159.jpg</td>\n      <td>Rock</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_image_588.jpg</td>\n      <td>Rock</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_image_1165.jpg</td>\n      <td>Paper</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_image_1171.jpg</td>\n      <td>Scissors</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_image_239.jpg</td>\n      <td>Paper</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'image': test_df['filepath'].apply(lambda x: os.path.basename(x)), 'predicted_class': y_pred_classes}\n",
    "df = pd.DataFrame(data=data)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:29:49.061241Z",
     "start_time": "2023-12-06T14:29:49.055118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(1350, 2)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:29:50.064409Z",
     "start_time": "2023-12-06T14:29:50.057640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "df.to_csv('out/submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:34:49.107110Z",
     "start_time": "2023-12-06T14:34:49.087071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:34:24.027514Z",
     "start_time": "2023-12-06T14:34:23.993361Z"
    }
   }
  }
 ]
}
